

<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
    

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

 


      <title>【机器学习】四层人工神经网络拟合二元二次函数 - </title>

  <meta name="description" content="四层人工神经网络拟合二元二次函数
如果想了解人工神经网络，请认真阅读每个字，字字珠玑。😂
核心代码:
      、、、、、、、、、、
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(2, 40)
        self.fc2 = nn.Linear(40, 40)
        self.fc3 =nn.Linear(40, 24)
        self.fc4 =nn.Linear(24, 1)
    def forward(self,x):
        return self.fc4(t.relu(self.fc3(t.relu(self.fc2(t.relu(self.fc1(x)))))))

def train(epoch,model,opt,lossfn,tu,tc):
    for i in range(1,epoch&#43;1):
        tp=model(tu)
        loss=lossfn(tp,tc)
        opt.zero_grad()
        loss.backward()
        opt.step()
        if i % 10 == 0 or i == 1:
            print(&#39;Epoch %d, Loss %f&#39; % (i, float(loss)))
    return model
def f(x,x2):
    return x**2&#43;x2

PATH = &#34;cyNN.pt&#34;
cyNN=t.load(PATH)
cyNN.eval()
opt=optim.Adam(cyNN.parameters(),lr=1e-7)
    、、、、、、、、、、
我们这个模型拟合的函数是：f(x,x2)=x^2&#43;x2
最最重要的核心调用框架


神经网络解释
这是一个四层人工神经网络，拟合二元二次函数。
输入层有两个神经元，输出层有一个神经元，中间两层各有40个神经元，最后一层有24个神经元。激活函数使用的是ReLU，优化器使用的是Adam，学习率为1e-7，损失函数使用的是MSELoss。
输入层：2个神经元  （表示两个自变量）
隐藏层1：40个神经元
隐藏层2：40个神经元
隐藏层3：24个神经元
输出层：1个神经元   （表示一个因变量）
激活函数：ReLU （线性整流函数）
优化器：Adam 
学习率：1e-7 
损失函数：MSELoss(即均方误差，也就是绝对误差的平方)
结构图

(一目了然这个属于是=。=）"><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "Juiceright",
    
    "url": "https:\/\/cywd123.github.io\/"
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "",
  "url": "https:\/\/cywd123.github.io\/"
  
  
  
  
}
</script>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "item": {
          "@id": "https:\/\/cywd123.github.io\/",
          "name": "home"
        }
    },{
        "@type": "ListItem",
        "position": 3,
        "item": {
          "@id": "https:\/\/cywd123.github.io\/posts\/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9B%E5%B1%82%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%8B%9F%E5%90%88%E4%BA%8C%E5%85%83%E4%BA%8C%E6%AC%A1%E5%87%BD%E6%95%B0\/",
          "name": "【机器学习】四层人工神经网络拟合二元二次函数"
        }
    }]
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "author": {
    "name" : ""
  },
  "headline": "【机器学习】四层人工神经网络拟合二元二次函数",
  "description" : "四层人工神经网络拟合二元二次函数 如果想了解人工神经网络，请认真阅读每个字，字字珠玑。😂\n核心代码:\n、、、、、、、、、、 class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.fc1 = nn.Linear(2, 40) self.fc2 = nn.Linear(40, 40) self.fc3 =nn.Linear(40, 24) self.fc4 =nn.Linear(24, 1) def forward(self,x): return self.fc4(t.relu(self.fc3(t.relu(self.fc2(t.relu(self.fc1(x))))))) def train(epoch,model,opt,lossfn,tu,tc): for i in range(1,epoch\u002b1): tp=model(tu) loss=lossfn(tp,tc) opt.zero_grad() loss.backward() opt.step() if i % 10 == 0 or i == 1: print(\u0026#39;Epoch %d, Loss %f\u0026#39; % (i, float(loss))) return model def f(x,x2): return x**2\u002bx2 PATH = \u0026#34;cyNN.pt\u0026#34; cyNN=t.load(PATH) cyNN.eval() opt=optim.Adam(cyNN.parameters(),lr=1e-7) 、、、、、、、、、、 我们这个模型拟合的函数是：f(x,x2)=x^2\u002bx2\n最最重要的核心调用框架 神经网络解释 这是一个四层人工神经网络，拟合二元二次函数。\n输入层有两个神经元，输出层有一个神经元，中间两层各有40个神经元，最后一层有24个神经元。激活函数使用的是ReLU，优化器使用的是Adam，学习率为1e-7，损失函数使用的是MSELoss。\n输入层：2个神经元 （表示两个自变量） 隐藏层1：40个神经元 隐藏层2：40个神经元 隐藏层3：24个神经元 输出层：1个神经元 （表示一个因变量） 激活函数：ReLU （线性整流函数） 优化器：Adam 学习率：1e-7 损失函数：MSELoss(即均方误差，也就是绝对误差的平方) 结构图 (一目了然这个属于是=。=）\n",
  "inLanguage" : "en",
  "wordCount":  112 ,
  "datePublished" : "2023-03-29T17:54:00\u002b00:00",
  "dateModified" : "2025-12-01T10:19:20\u002b00:00",
  "image" : "https:\/\/cywd123.github.io\/",
  "keywords" : [ "编程, 机器学习" ],
  "mainEntityOfPage" : "https:\/\/cywd123.github.io\/posts\/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9B%E5%B1%82%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%8B%9F%E5%90%88%E4%BA%8C%E5%85%83%E4%BA%8C%E6%AC%A1%E5%87%BD%E6%95%B0\/",
  "publisher" : {
    "@type": "Organization",
    "name" : "https:\/\/cywd123.github.io\/",
    "logo" : {
        "@type" : "ImageObject",
        "url" : "https:\/\/cywd123.github.io\/",
        "height" :  60 ,
        "width" :  60
    }
  }
}
</script>


<meta property="og:title" content="【机器学习】四层人工神经网络拟合二元二次函数" />
<meta property="og:description" content="四层人工神经网络拟合二元二次函数
如果想了解人工神经网络，请认真阅读每个字，字字珠玑。😂
核心代码:
      、、、、、、、、、、
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(2, 40)
        self.fc2 = nn.Linear(40, 40)
        self.fc3 =nn.Linear(40, 24)
        self.fc4 =nn.Linear(24, 1)
    def forward(self,x):
        return self.fc4(t.relu(self.fc3(t.relu(self.fc2(t.relu(self.fc1(x)))))))

def train(epoch,model,opt,lossfn,tu,tc):
    for i in range(1,epoch&#43;1):
        tp=model(tu)
        loss=lossfn(tp,tc)
        opt.zero_grad()
        loss.backward()
        opt.step()
        if i % 10 == 0 or i == 1:
            print(&#39;Epoch %d, Loss %f&#39; % (i, float(loss)))
    return model
def f(x,x2):
    return x**2&#43;x2

PATH = &#34;cyNN.pt&#34;
cyNN=t.load(PATH)
cyNN.eval()
opt=optim.Adam(cyNN.parameters(),lr=1e-7)
    、、、、、、、、、、
我们这个模型拟合的函数是：f(x,x2)=x^2&#43;x2
最最重要的核心调用框架


神经网络解释
这是一个四层人工神经网络，拟合二元二次函数。
输入层有两个神经元，输出层有一个神经元，中间两层各有40个神经元，最后一层有24个神经元。激活函数使用的是ReLU，优化器使用的是Adam，学习率为1e-7，损失函数使用的是MSELoss。
输入层：2个神经元  （表示两个自变量）
隐藏层1：40个神经元
隐藏层2：40个神经元
隐藏层3：24个神经元
输出层：1个神经元   （表示一个因变量）
激活函数：ReLU （线性整流函数）
优化器：Adam 
学习率：1e-7 
损失函数：MSELoss(即均方误差，也就是绝对误差的平方)
结构图

(一目了然这个属于是=。=）">
<meta property="og:url" content="https://cywd123.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9B%9B%E5%B1%82%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%8B%9F%E5%90%88%E4%BA%8C%E5%85%83%E4%BA%8C%E6%AC%A1%E5%87%BD%E6%95%B0/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="Juiceright" />

  <meta name="twitter:title" content="【机器学习】四层人工神经网络拟合二元二次函数" />
  <meta name="twitter:description" content="四层人工神经网络拟合二元二次函数
如果想了解人工神经网络，请认真阅读每个字，字字珠玑。😂
核心代码:
      、、、、、、、、、、
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(2, 40)
        self. …">
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="generator" content="Hugo 0.152.2">
  <link rel="alternate" href="https://cywd123.github.io/index.xml" type="application/rss+xml" title="Juiceright"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css" integrity="sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v7.0.1/css/brands.css" integrity="sha384-+eXGm6TmVoCZR1gX03US+L++L2mJIfOvp2X0+luTuEktXaF5F+e3zn0sO0HBvOyT" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v7.0.1/css/fontawesome.css" integrity="sha384-B5nyPZa7e84uCJEYHtevCdVYtQosWsbDSRtq3cy/jeSVtQW05GL8CKXO7waXsjPK" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v7.0.1/css/regular.css" integrity="sha384-V71z/A/p/DGaZAryHhiSXRQj8HdQmK2nBgL2bX23MGD+h6ZKpyxOO76f5eSXmIaj" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v7.0.1/css/solid.css" integrity="sha384-1IIShlrK5iYgvS7OAgIH3prz4RAFP7hHZ2MaLIb9l3+trFwwnw/NdCWcUHlymZDU" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v7.0.1/css/svg.css" integrity="sha384-iBa7uugTOHXqQ2ngvDYJyKrPPQbd9n2P3EQe+o/0+HZe5TNvV+LO5X0lLLUrXLHP" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v7.0.1/css/svg-with-js.css" integrity="sha384-STWnS5AGz6M2YxsnGAd536EqcE2y+ktGovMMuhtXLsCBtl7lujeQj2eN4eDxa57x" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v7.0.1/css/v4-font-face.css" integrity="sha384-fH83IkgQi7kturzlxpXfNdsR8aUOcqj5HUORRVnSvJgObZkIw6aqKAaQx20IWyB/" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v7.0.1/css/v4-shims.css" integrity="sha384-cCODJHSivNBsaHei/8LC0HUD58kToSbDU+xT7Rs51BO1v/IvgT/uM0W6xMoUqKfn" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v7.0.1/css/v5-font-face.css" integrity="sha384-atSdF89mIn15dv+o2LKkDM6mCh3hwh6A7mwZ6F2it/kenqZbMu+QW/ye1OG4XSWV" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/css/bootstrap.min.css" integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu" crossorigin="anonymous"><link rel="stylesheet" href="https://cywd123.github.io/css/main.css" /><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" /><link rel="stylesheet" href="https://cywd123.github.io/css/syntax.css" /><link rel="stylesheet" href="https://cywd123.github.io/css/codeblock.css" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css" integrity="sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">

  </head>
  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="https://cywd123.github.io/">Juiceright</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        

        

        
      </ul>
    </div>

    

  </div>
</nav>




    


<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>


  
  
  






  

  <header class="header-section ">
    
    
    <div class="intro-header no-img">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="posts-heading">
              
                <h1>【机器学习】四层人工神经网络拟合二元二次函数</h1>
              
              
                <hr class="small">
              
              
              
            </div>
          </div>
        </div>
      </div>
    </div>
  
  </header>


    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        <h1 id="四层人工神经网络拟合二元二次函数">四层人工神经网络拟合二元二次函数</h1>
<p>如果想了解人工神经网络，请认真阅读每个字，字字珠玑。😂</p>
<p>核心代码:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>      <span style="color:#960050;background-color:#1e0010">、、、、、、、、、、</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Net</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">__init__</span>(self):
</span></span><span style="display:flex;"><span>        super(Net, self)<span style="color:#f92672">.</span><span style="color:#a6e22e">__init__</span>()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fc1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">40</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fc2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">40</span>, <span style="color:#ae81ff">40</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fc3 <span style="color:#f92672">=</span>nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">40</span>, <span style="color:#ae81ff">24</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>fc4 <span style="color:#f92672">=</span>nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">24</span>, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self,x):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> self<span style="color:#f92672">.</span>fc4(t<span style="color:#f92672">.</span>relu(self<span style="color:#f92672">.</span>fc3(t<span style="color:#f92672">.</span>relu(self<span style="color:#f92672">.</span>fc2(t<span style="color:#f92672">.</span>relu(self<span style="color:#f92672">.</span>fc1(x)))))))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">train</span>(epoch,model,opt,lossfn,tu,tc):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>,epoch<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>        tp<span style="color:#f92672">=</span>model(tu)
</span></span><span style="display:flex;"><span>        loss<span style="color:#f92672">=</span>lossfn(tp,tc)
</span></span><span style="display:flex;"><span>        opt<span style="color:#f92672">.</span>zero_grad()
</span></span><span style="display:flex;"><span>        loss<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>        opt<span style="color:#f92672">.</span>step()
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> i <span style="color:#f92672">%</span> <span style="color:#ae81ff">10</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">or</span> i <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">&#39;Epoch </span><span style="color:#e6db74">%d</span><span style="color:#e6db74">, Loss </span><span style="color:#e6db74">%f</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span> (i, float(loss)))
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> model
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">f</span>(x,x2):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> x<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span><span style="color:#f92672">+</span>x2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>PATH <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;cyNN.pt&#34;</span>
</span></span><span style="display:flex;"><span>cyNN<span style="color:#f92672">=</span>t<span style="color:#f92672">.</span>load(PATH)
</span></span><span style="display:flex;"><span>cyNN<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>opt<span style="color:#f92672">=</span>optim<span style="color:#f92672">.</span>Adam(cyNN<span style="color:#f92672">.</span>parameters(),lr<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-7</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#960050;background-color:#1e0010">、、、、、、、、、、</span>
</span></span></code></pre></div><p>我们这个模型拟合的函数是：f(x,x2)=x^2+x2</p>
<h4 id="最最重要的核心调用框架">最最重要的核心调用框架</h4>
<p><img src="/images/1741976905763.jpg" alt=""></p>
<hr>
<h2 id="神经网络解释">神经网络解释</h2>
<p>这是一个四层人工神经网络，拟合二元二次函数。</p>
<p>输入层有两个神经元，输出层有一个神经元，中间两层各有40个神经元，最后一层有24个神经元。激活函数使用的是ReLU，优化器使用的是Adam，学习率为1e-7，损失函数使用的是MSELoss。</p>
<pre tabindex="0"><code>输入层：2个神经元  （表示两个自变量）
隐藏层1：40个神经元
隐藏层2：40个神经元
隐藏层3：24个神经元
输出层：1个神经元   （表示一个因变量）
激活函数：ReLU （线性整流函数）
优化器：Adam 
学习率：1e-7 
损失函数：MSELoss(即均方误差，也就是绝对误差的平方)
</code></pre><h4 id="结构图">结构图</h4>
<p><img src="/images/1741976913419.jpg" alt=""><br>
(一目了然这个属于是=。=）</p>
<h4 id="激活函数">激活函数</h4>
<p>这个激活函数采用的是ReLU，即线性整流函数，公式如下：<br>
<img src="/images/1741976920065.jpg" alt=""><br>
这个函数的特点是，当x&gt;0时，y=x，当x&lt;0时，y=0，这样就可以避免梯度消失的问题。同时，这个函数非常简单（数学公式只是 f(x)=max(0,x)</p>
<h4 id="优化器">优化器</h4>
<p>这个优化器采用的是Pytorch内置的Adam，这个优化器是基于梯度下降的优化器，它的优点是，不需要精确设置学习率，而且可以自动调整学习率。而且更重要的是它对输入的数据不敏感，不需要对数据进行归一化处理。（可以同时处理不同量级的输入数据，例如同时处理0.1和10000的数据）</p>
<h4 id="损失函数">损失函数</h4>
<p>这个损失函数采用的是MSELoss，即均方误差，也就是绝对误差的平方。没啥好说的。</p>
<hr>
<h2 id="测试环节">测试环节</h2>
<p>这里我用了一个简单的测试方法，就是随机输入二元二次函数的数据，然后用这个神经网络进行拟合，看看拟合的效果如何。</p>
<p><img src="/images/1741976925953.jpg" alt=""></p>
<p><img src="/images/1741976929471.jpg" alt=""></p>
<p>可以看到，这个神经网络拟合的效果还是不错的(拟合误差在2%以内)，而且这个神经网络的结构也是比较简单的，如果我们把神经网络的层数增加，神经元的数量增加，那么拟合的效果肯定会更好。</p>
<hr>
<h2 id="反思">反思</h2>
<h4 id="缺点">缺点</h4>
<ol>
<li>这个神经网络的缺点是，它的结构依旧比较简单。如果我们把神经网络的层数增加，神经元的数量增加，那么拟合的效果肯定会更好。然鹅在训练深度神经网络时，模型的性能随着架构深度的增加而下降。这被称为“退化问题”。这样显然是不划算的。。。。。。</li>
<li>出现了过拟合的现象（课本上讲解的过拟合现象）<br>
<img src="/images/1741976935613.jpg" alt=""></li>
</ol>
<p>显然，上方的拟合图像才是我们想要的函数图像。<br>
但过多次训练后，这个神经网络的拟合会趋向于下方图像，这就是过拟合的现象。<br>
专业来讲：过拟合现象是指一个模型在训练集上表现优异，但在测试集上表现一般，甚至无法正确预测测试集数据的现象。<br>
所以，这个模型不能过度重复训练，否则会出现过拟合的现象。但是重复训练减少了，又会拟合不足，所以我们需要找到一个平衡点。只能说（道阻且长，行则将至）</p>
<h4 id="优点">优点</h4>
<ol>
<li>这个神经网络的优点是，它的结构比较简单，所以训练速度比较快，而且拟合的效果也还不错。</li>
<li>这个是前面机器学习的“升 级 版”，构建了前面没有的四层人工神经网络，学习能力更强了。</li>
</ol>


        
          <div class="blog-tags">
            
              
              <a href="https://cywd123.github.io/tags/%E7%BC%96%E7%A8%8B/">编程</a>&nbsp;
            
              
              <a href="https://cywd123.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>&nbsp;
            
          </div>
        

        

        
      </article>

      
        <ul class="pager blog-pager">
          
            <li class="previous">
              <a href="https://cywd123.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8F%AF%E6%8B%9F%E5%90%88%E4%BB%BB%E6%84%8F%E7%BA%BF%E6%80%A7%E5%87%BD%E6%95%B0%E7%9A%84%E5%B0%8F%E7%8E%A9%E6%84%8F%E5%84%BF/" data-toggle="tooltip" data-placement="top" title="【机器学习】可拟合任意线性函数的小玩意儿">&larr; Previous Post</a>
            </li>
          
          
            <li class="next">
              <a href="https://cywd123.github.io/posts/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB%E5%88%86%E7%B1%BBmnist%E6%95%B0%E6%8D%AE%E9%9B%86/" data-toggle="tooltip" data-placement="top" title="【深度学习】手写数字图像识别分类（MNIST数据集）">Next Post &rarr;</a>
            </li>
          
        </ul>
      


      

    </div>
  </div>
</div>

      <footer>
  <div class="container">
    
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
          
        </ul>
        <p class="credits copyright text-muted">
          

          &nbsp;&bull;&nbsp;&copy;
          
            2025
          

          
            &nbsp;&bull;&nbsp;
            <a href="https://cywd123.github.io/">Juiceright</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="https://gohugo.io">Hugo v0.152.2</a> powered &nbsp;&bull;&nbsp; Theme <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a> adapted from <a href="https://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a>
          
        </p>
      </div>
    </div>
  </div>
</footer><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js" integrity="sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
<script src="https://code.jquery.com/jquery-3.7.0.slim.min.js" integrity="sha384-w5y/xIeYixWvfM+A1cEbmHPURnvyqmVg5eVENruEdDjcyRLUSNej7512JQGspFUr" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/js/bootstrap.min.js" integrity="sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd" crossorigin="anonymous"></script>

<script src="https://cywd123.github.io/js/main.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js" integrity="sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js" integrity="sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q" crossorigin="anonymous"></script><script src="https://cywd123.github.io/js/load-photoswipe.js"></script>










    
  </body>
</html>

